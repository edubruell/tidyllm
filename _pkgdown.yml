url: https://edubruell.github.io/tidyllm/
template:
  bootstrap: 5
  bootswatch: litera  
  assets:
    css: ["extra.scss"]

reference:
  - title: "LLM Message Handling"
    desc: >
      Functions for creating, managing, and retrieving messages and metadata.
    contents:
      - llm_message
      - df_llm_message
      - ends_with("reply")
      - ends_with("reply_data")
      - ends_with("user_message")
      - get_metadata
      - tidyllm_schema
      - rate_limit_info

  - title: "Tidyllm Main Verbs"
    desc: >
      Core verbs facilitating interactions with LLMs, including sending messages,
      generating embeddings, and managing batch requests.
    contents:
      - chat
      - embed
      - send_batch
      - check_batch
      - fetch_batch
      - list_batches

  - title: "API Provider Functions"
    desc: >
      Functions interfacing with various API providers called from main verbs
    contents:
      - openai
      - claude
      - gemini
      - groq
      - mistral
      - ollama
      - azure_openai
      - chatgpt

  - title: "OpenAI-Specific Functions"
    desc: >
      Functions for OpenAI services, including chat interactions, batch processing and
      embedding generation.
    contents:
      - openai_chat
      - send_openai_batch
      - check_openai_batch
      - fetch_openai_batch
      - list_openai_batches
      - cancel_openai_batch
      - openai_embedding

  - title: "Claude-Specific Functions"
    desc: >
      Functions designed for Claude services for chat interactions and
      batch processing.
    contents:
      - claude_chat
      - send_claude_batch
      - check_claude_batch
      - fetch_claude_batch
      - list_claude_batches

  - title: "Gemini-Specific Functions"
    desc: >
      Functions specific to Google Gemini services, including chat, embedding,
      and file management operations.
    contents:
      - gemini_chat
      - gemini_embedding
      - gemini_upload_file
      - gemini_list_files
      - gemini_file_metadata
      - gemini_delete_file
  
  - title: "Ollama-Specific Functions"
    desc: >
      Functions for engaging with Ollama services, including chat, embedding,
      and model management.
    contents:
      - ollama_chat
      - ollama_embedding
      - send_ollama_batch
      - ollama_download_model
      - ollama_list_models
      
  - title: "Mistral-Specific Functions"
    desc: >
      Functions for interacting with the Mistral API .
    contents:
      - mistral_chat
      - mistral_embedding
      - send_mistral_batch
      - check_mistral_batch
      - fetch_mistral_batch
      - list_mistral_batches
      
  - title: "Perplexity-Specific Functions"
    desc: >
      Functions for the Perplexity API
    contents:
      - perplexity_chat
      - perplexity
      
  - title: "Groq-Specific Functions"
    desc: >
      Functions for interacting with Groq services, such as chat and transcription.
    contents:
      - groq_chat
      - groq_transcribe
      
  - title: "Azure-Specific Functions"
    desc: >
      Functions for interacting with the Azure OpenAI API .
    contents:
      - azure_openai_chat
      - azure_openai_embedding
      - send_azure_openai_batch
      - check_azure_openai_batch
      - list_azure_openai_batches
      - fetch_azure_openai_batch
  
  - title: "PDF Processing"
    desc: >
      Processing PDF documents, enabling page-by-page analysis.
    contents:
      - pdf_page_batch      

  - title: "Internals"
    desc: >
      Main definition of the LLMMessage object at the core of most tidyllm workflows 
    contents:
      - LLMMessage


