<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Changelog • tidyllm</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Changelog"><meta property="og:image" content="https://edubruell.github.io/tidyllm/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">tidyllm</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/tidyllm.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/tidyllm_classifiers.html">Classifying Texts with tidyllm</a></li>
    <li><a class="dropdown-item" href="../articles/tidyllm-pdfquestions.html">Structured Question Answering from PDFs</a></li>
    <li><a class="dropdown-item" href="../articles/tidyllm-synthetic-data.html">Generate Synthetic Data with tidyllm</a></li>
  </ul></li>
<li class="active nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/edubruell/tidyllm/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-news">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Changelog</h1>
      <small>Source: <a href="https://github.com/edubruell/tidyllm/blob/HEAD/NEWS.md" class="external-link"><code>NEWS.md</code></a></small>
    </div>

    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.2.0" id="version-020">Version 0.2.0<a class="anchor" aria-label="anchor" href="#version-020"></a></h2><p class="text-muted">CRAN release: 2024-11-07</p>
<p>New CRAN release. Largest changes compared to <strong>0.1.0</strong>:</p>
<p><strong>Major Features:</strong></p>
<ul><li>Batch Request Support: Added support for batch requests with both Anthropic and OpenAI APIs, enabling large-scale request handling.</li>
<li>Schema Support: Improved structured outputs in JSON mode with advanced <code>.json_schema</code> handling in <code><a href="../reference/openai.html">openai()</a></code>, enhancing support for well-defined JSON responses.</li>
<li>Azure OpenAI Integration: Introduced <code><a href="../reference/azure_openai.html">azure_openai()</a></code> function for accessing the Azure OpenAI service, with full support for rate-limiting and batch operations tailored to Azure’s API structure.</li>
<li>Embedding Model Support: Added embedding generation functions for the OpenAI, Ollama, and Mistral APIs, supporting message content and media embedding.</li>
<li>Mistral API Integration: New <code><a href="../reference/mistral.html">mistral()</a></code> function provides full support for Mistral models hosted in the EU, including rate-limiting and streaming capabilities.</li>
<li>PDF Batch Processing: Introduced the <code><a href="../reference/pdf_page_batch.html">pdf_page_batch()</a></code> function, which processes PDFs page by page, allowing users to define page-specific prompts for detailed analysis.</li>
<li>Support for OpenAI-compatible APIs: Introduced a <code>.compatible</code> argument (and flexible url and path) in <code><a href="../reference/openai.html">openai()</a></code> to allow compatibility with third-party OpenAI-compatible APIs.</li>
</ul><p><strong>Improvements:</strong></p>
<ul><li>API Format Refactoring: Complete refactor of <code>to_api_format()</code> to reduce code duplication, simplify API format generation, and improve maintainability.</li>
<li>Improved Error Handling: Enhanced input validation and error messaging for all API-functions functions, making troubleshooting easier.</li>
<li>Rate-Limiting Enhancements: Updated rate limiting to use <code><a href="https://httr2.r-lib.org/reference/req_retry.html" class="external-link">httr2::req_retry()</a></code> in addition to the rate-limit tracking functions in tidyllm, using 429 headers to wait for rate limit resets.</li>
<li>Expanded Testing: Added comprehensive tests for API functions using <code>httptest2</code>
</li>
</ul><p><strong>Breaking Changes:</strong></p>
<ul><li>Redesigned Reply Functions: <code><a href="../reference/get_reply.html">get_reply()</a></code> was split into <code><a href="../reference/get_reply.html">get_reply()</a></code> for text outputs and <code><a href="../reference/get_reply_data.html">get_reply_data()</a></code> for structured outputs, improving type stability compared to an earlier function that had different outputs based on a <code>.json</code>-arguement.</li>
<li>Deprecation of <code><a href="../reference/chatgpt.html">chatgpt()</a></code>: The <code><a href="../reference/chatgpt.html">chatgpt()</a></code> function has been deprecated in favor of <code><a href="../reference/openai.html">openai()</a></code> for feature alignment and improved consistency.</li>
</ul><p><strong>Minor Updates and Bug Fixes:</strong></p>
<ul><li>Expanded PDF Support in <code><a href="../reference/llm_message.html">llm_message()</a></code>: Allows extraction of specific page ranges from PDFs, improving flexibility in document handling.</li>
<li>New <code><a href="../reference/ollama_download_model.html">ollama_download_model()</a></code> function to download models from the Ollama API</li>
<li>All sequential chat API functions now support streaming</li>
</ul></div>
    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.1.11" id="version-0111">Version 0.1.11<a class="anchor" aria-label="anchor" href="#version-0111"></a></h2>
<div class="section level3">
<h3 id="major-features-0-1-11">Major Features<a class="anchor" aria-label="anchor" href="#major-features-0-1-11"></a></h3>
<ul><li>Support for both the Anthropic and the OpenAI batch request API added</li>
<li>New <code>.compatible</code>-arguement in <code><a href="../reference/openai.html">openai()</a></code> to allow working with compatible third party APIs</li>
</ul></div>
<div class="section level3">
<h3 id="improvements-0-1-11">Improvements<a class="anchor" aria-label="anchor" href="#improvements-0-1-11"></a></h3>
<ul><li>
<strong>Complete refactor of <code>to_api_format()</code></strong>: API format generation now has much less code duplication and is more maintainable.</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.1.10" id="version-0110">Version 0.1.10<a class="anchor" aria-label="anchor" href="#version-0110"></a></h2>
<div class="section level3">
<h3 id="breaking-changes-0-1-10">Breaking Changes<a class="anchor" aria-label="anchor" href="#breaking-changes-0-1-10"></a></h3>
<ul><li>
<code><a href="../reference/get_reply.html">get_reply()</a></code> was split into two type-stable functions: <code><a href="../reference/get_reply.html">get_reply()</a></code> for text and <code><a href="../reference/get_reply_data.html">get_reply_data()</a></code> for structured outputs.</li>
</ul></div>
<div class="section level3">
<h3 id="improvements-0-1-10">Improvements<a class="anchor" aria-label="anchor" href="#improvements-0-1-10"></a></h3>
<ul><li>
<strong>Rate limiting updated to use <code><a href="https://httr2.r-lib.org/reference/req_retry.html" class="external-link">httr2::req_retry()</a></code></strong>: Rate limiting now uses the right 429 headers where they come.</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.1.9" id="version-019">Version 0.1.9<a class="anchor" aria-label="anchor" href="#version-019"></a></h2>
<div class="section level3">
<h3 id="major-features-0-1-9">Major Features<a class="anchor" aria-label="anchor" href="#major-features-0-1-9"></a></h3>
<ul><li><p><strong>Enhanced Input Validation</strong>: All API functions now have improved input validation, ensuring better alignment with API documentation</p></li>
<li><p><strong>Improved error handling</strong> More human-readable error messages for failed requests from the API</p></li>
<li><p><strong>Advanced JSON Mode in <code><a href="../reference/openai.html">openai()</a></code></strong>: The <code><a href="../reference/openai.html">openai()</a></code> function now supports advanced <code>.json_schemas</code>, allowing structured output in JSON mode for more precise responses.</p></li>
<li><p><strong>Reasoning Models Support</strong>: Support for O1 reasoning models has been added, with better handling of system prompts in the <code><a href="../reference/openai.html">openai()</a></code> function.</p></li>
<li><p><strong>Streaming callback functions refactored:</strong> Given that the streaming callback format for Open AI, Mistral and Groq is nearly identical the three now rely on the same callback function.</p></li>
</ul></div>
<div class="section level3">
<h3 id="breaking-changes-0-1-9">Breaking Changes<a class="anchor" aria-label="anchor" href="#breaking-changes-0-1-9"></a></h3>
<ul><li>
<strong><code><a href="../reference/chatgpt.html">chatgpt()</a></code> Deprecated</strong>: The <code><a href="../reference/chatgpt.html">chatgpt()</a></code> function has been deprecated in favor of <code><a href="../reference/openai.html">openai()</a></code>. Users should migrate to <code><a href="../reference/openai.html">openai()</a></code> to take advantage of the new features and enhancements.</li>
</ul></div>
<div class="section level3">
<h3 id="improvements-0-1-9">Improvements<a class="anchor" aria-label="anchor" href="#improvements-0-1-9"></a></h3>
<ul><li>
<strong>Better Error Handling</strong>: The <code><a href="../reference/openai.html">openai()</a></code>, <code><a href="../reference/ollama.html">ollama()</a></code>, and <code><a href="../reference/claude.html">claude()</a></code> functions now return more informative error messages when API calls fail, helping with debugging and troubleshooting.</li>
</ul><hr></div>
</div>
    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.1.8" id="version-018">Version 0.1.8<a class="anchor" aria-label="anchor" href="#version-018"></a></h2>
<div class="section level3">
<h3 id="major-features-0-1-8">Major Features<a class="anchor" aria-label="anchor" href="#major-features-0-1-8"></a></h3>
<ul><li>
<strong>Embedding Models Support:</strong> Embedding model support for three APIs:
<ul><li>Embedding functions process message histories and combine text from message content and media attachments for embedding models.</li>
<li>
<code><a href="../reference/ollama_embedding.html">ollama_embedding()</a></code> to generate embeddings using the Ollama API.</li>
<li>
<code><a href="../reference/openai_embedding.html">openai_embedding()</a></code> to generate embeddings using the OpenAI API.</li>
<li>
<code><a href="../reference/mistral_embedding.html">mistral_embedding()</a></code> to generate embeddings using the Mistral API.</li>
</ul></li>
</ul></div>
<div class="section level3">
<h3 id="improvements-0-1-8">Improvements<a class="anchor" aria-label="anchor" href="#improvements-0-1-8"></a></h3>
<ul><li>
<strong>PDF Page Support in <code><a href="../reference/llm_message.html">llm_message()</a></code>:</strong> The <code><a href="../reference/llm_message.html">llm_message()</a></code> function now supports specifying a range of pages in a PDF by passing a list with <code>filename</code>, <code>start_page</code>, and <code>end_page</code>. This allows users to extract and process specific pages of a PDF.</li>
</ul><hr></div>
</div>
    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.1.7" id="version-017">Version 0.1.7<a class="anchor" aria-label="anchor" href="#version-017"></a></h2>
<div class="section level3">
<h3 id="major-features-0-1-7">Major Features<a class="anchor" aria-label="anchor" href="#major-features-0-1-7"></a></h3>
<ul><li>
<strong>PDF Page Batch Processing</strong>: Introduced the <code><a href="../reference/pdf_page_batch.html">pdf_page_batch()</a></code> function, which processes PDF files page by page, extracting text and converting each page into an image, allowing for a general prompt or page-specific prompts. The function generates a list of <code>LLMMessage</code> objects that can be sent to an API and work with the batch-API functions in <strong>tidyllm</strong>.</li>
</ul><hr></div>
</div>
    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.1.6" id="version-016">Version 0.1.6<a class="anchor" aria-label="anchor" href="#version-016"></a></h2>
<div class="section level3">
<h3 id="major-features-0-1-6">Major Features<a class="anchor" aria-label="anchor" href="#major-features-0-1-6"></a></h3>
<ul><li>
<strong>Support for the Mistral API</strong>: New <code><a href="../reference/mistral.html">mistral()</a></code> function to use Mistral Models on Le Platforme on servers hosted in the EU, with rate-limiting and streaming support.</li>
</ul><hr></div>
</div>
    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.1.5" id="version-015">Version 0.1.5<a class="anchor" aria-label="anchor" href="#version-015"></a></h2>
<div class="section level3">
<h3 id="major-features-0-1-5">Major Features<a class="anchor" aria-label="anchor" href="#major-features-0-1-5"></a></h3>
<ul><li>
<strong>Message Retrieval Functions</strong>: Added functions to retrieve single messages from conversations:
<ul><li>
<code><a href="../reference/last_user_message.html">last_user_message()</a></code> pulls the last message the user sent.</li>
<li>
<code><a href="../reference/get_reply.html">get_reply()</a></code> gets the assistant reply at a given index of assistant messages.</li>
<li>
<code><a href="../reference/get_user_message.html">get_user_message()</a></code> gets the user message at a given index of user messages.</li>
</ul></li>
</ul></div>
<div class="section level3">
<h3 id="improvements-0-1-5">Improvements<a class="anchor" aria-label="anchor" href="#improvements-0-1-5"></a></h3>
<ul><li>
<strong>Easier Troubleshooting in API-function</strong>: All API functions now support the <code>.dry_run</code> argument, allowing users to generate an <code>httr2</code>-request for easier debugging and inspection.</li>
<li>
<strong>API Function Tests:</strong> Implemented <code>httptest2</code>-based tests with mock responses for all API functions, covering both basic functionality and rate-limiting.</li>
</ul><hr></div>
</div>
    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.1.4" id="version-014">Version 0.1.4<a class="anchor" aria-label="anchor" href="#version-014"></a></h2>
<div class="section level3">
<h3 id="major-features-0-1-4">Major Features<a class="anchor" aria-label="anchor" href="#major-features-0-1-4"></a></h3>
<ul><li>
<strong>New Ollama functions</strong>:
<ul><li>
<strong>Model Download:</strong> Introduced the <code><a href="../reference/ollama_download_model.html">ollama_download_model()</a></code> function to download models from the Ollama API. It supports a streaming mode that provides live progress bar updates on the download progress.</li>
</ul></li>
</ul></div>
<div class="section level3">
<h3 id="improvements-0-1-4">Improvements<a class="anchor" aria-label="anchor" href="#improvements-0-1-4"></a></h3>
<ul><li>Refactoring of <code><a href="../reference/llm_message.html">llm_message()</a></code>
</li>
</ul><hr></div>
</div>
    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.1.3" id="version-013">Version 0.1.3<a class="anchor" aria-label="anchor" href="#version-013"></a></h2>
<div class="section level3">
<h3 id="major-features-0-1-3">Major Features<a class="anchor" aria-label="anchor" href="#major-features-0-1-3"></a></h3>
<ul><li>The <code><a href="../reference/groq.html">groq()</a></code> function now supports images.</li>
<li>More complete streaming support across API-functions.</li>
</ul></div>
<div class="section level3">
<h3 id="breaking-changes-0-1-3">Breaking Changes<a class="anchor" aria-label="anchor" href="#breaking-changes-0-1-3"></a></h3>
<ul><li>
<strong>Groq Models</strong>: System prompts are no longer sent for Groq models, since many models on Groq do not support them and all multimodal models on Groq disallow them.</li>
</ul><hr></div>
</div>
    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.1.2" id="version-012">Version 0.1.2<a class="anchor" aria-label="anchor" href="#version-012"></a></h2>
<div class="section level3">
<h3 id="improvements-0-1-2">Improvements<a class="anchor" aria-label="anchor" href="#improvements-0-1-2"></a></h3>
<ul><li>
<strong>New unit tests for <code><a href="../reference/llm_message.html">llm_message()</a></code></strong>.</li>
<li>Improvements in streaming functions.</li>
</ul><hr></div>
</div>
    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.1.1" id="version-011">Version 0.1.1<a class="anchor" aria-label="anchor" href="#version-011"></a></h2>
<div class="section level3">
<h3 id="major-features-0-1-1">Major Features<a class="anchor" aria-label="anchor" href="#major-features-0-1-1"></a></h3>
<ul><li><p><strong>JSON Mode</strong>: JSON mode is now more widely supported across all API functions, allowing for structured outputs when APIs support them. The <code>.json</code> argument is now passed only to API functions, specifying how the API should respond, and it is not needed anymore in <code><a href="../reference/last_reply.html">last_reply()</a></code>.</p></li>
<li><p><strong>Improved <code><a href="../reference/last_reply.html">last_reply()</a></code> Behavior</strong>: The behavior of the <code><a href="../reference/last_reply.html">last_reply()</a></code> function has changed. It now automatically handles JSON replies by parsing them into structured data and falling back to raw text in case of errors. You can still force raw text replies even for JSON output using the <code>.raw</code> argument.</p></li>
</ul></div>
<div class="section level3">
<h3 id="breaking-changes-0-1-1">Breaking Changes<a class="anchor" aria-label="anchor" href="#breaking-changes-0-1-1"></a></h3>
<ul><li>
<strong><code><a href="../reference/last_reply.html">last_reply()</a></code></strong>: The <code>.json</code> argument is no longer used, and JSON replies are automatically parsed. Use <code>.raw</code> to force raw text replies.</li>
</ul></div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Eduard Brüll.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer></div>





  </body></html>

