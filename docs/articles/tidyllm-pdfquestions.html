<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Structured Question Answering from PDFs • tidyllm</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Structured Question Answering from PDFs">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">tidyllm</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.3.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/tidyllm.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/tidyllm_classifiers.html">Classifying Texts with tidyllm</a></li>
    <li><a class="dropdown-item" href="../articles/tidyllm_embed.html">Embedding Models in tidyllm</a></li>
    <li><a class="dropdown-item" href="../articles/tidyllm_video.html">Video and Audio Data with the Gemini API</a></li>
    <li><a class="dropdown-item" href="../articles/tidyllm-pdfquestions.html">Structured Question Answering from PDFs</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/edubruell/tidyllm/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Structured Question Answering from PDFs</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/edubruell/tidyllm/blob/HEAD/vignettes/articles/tidyllm-pdfquestions.Rmd" class="external-link"><code>vignettes/articles/tidyllm-pdfquestions.Rmd</code></a></small>
      <div class="d-none name"><code>tidyllm-pdfquestions.Rmd</code></div>
    </div>

    
    
<p>Navigating through a large collection of academic papers can be
time-consuming, especially when you’re trying to extract specific
insights or determine the relevance of each document to your research.
With <strong>tidyllm</strong>, you can streamline this process by
automating the extraction of structured answers directly from PDF
documents using large language models.</p>
<p>Imagine you have a folder of papers on the economic effects of
generative AI, and you need to assess how each paper is related to your
own research interests. This article will guide you through setting up a
workflow that processes the first few pages of each paper, asks an AI
model targeted questions, and returns the answers in a structured format
— perfect for converting into a table for easy review and analysis.</p>
<div class="section level2">
<h2 id="example-workflow">Example Workflow<a class="anchor" aria-label="anchor" href="#example-workflow"></a>
</h2>
<p>Imagine your folder looks something like this—many downloaded papers,
but no structure yet:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org" class="external-link">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://edubruell.github.io/tidyllm/">tidyllm</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/list.files.html" class="external-link">dir</a></span><span class="op">(</span><span class="st">"aipapers"</span><span class="op">)</span></span>
<span><span class="co">##  [1] "2018_Felten_etal_AILinkOccupations.pdf"                                                           </span></span>
<span><span class="co">##  [2] "2024_Bick_etal_RapidAdoption.pdf"                                                                 </span></span>
<span><span class="co">##  [3] "2024_Caplin_etal_ABCsofAI.pdf"                                                                    </span></span>
<span><span class="co">##  [4] "2301.07543v1.pdf"                                                                                 </span></span>
<span><span class="co">##  [5] "2302.06590v1.pdf"                                                                                 </span></span>
<span><span class="co">##  [6] "2303.10130v5.pdf"                                                                                 </span></span>
<span><span class="co">##  [7] "488.pdf"                                                                                          </span></span>
<span><span class="co">##  [8] "88684e36-en.pdf"                                                                                  </span></span>
<span><span class="co">##  [9] "ABCs_AI_Oct2024.pdf"                                                                              </span></span>
<span><span class="co">## [10] "acemoglu-restrepo-2019-automation-and-new-tasks-how-technology-displaces-and-reinstates-labor.pdf"</span></span>
<span><span class="co">## [11] "BBD_GenAI_NBER_Sept2024.pdf"                                                                      </span></span>
<span><span class="co">## [12] "Deming-Ong-Summers-AESG-2024.pdf"                                                                 </span></span>
<span><span class="co">## [13] "dp22036.pdf"                                                                                      </span></span>
<span><span class="co">## [14] "FeltenRajSeamans_AIAbilities_AEA.pdf"                                                             </span></span>
<span><span class="co">## [15] "JEL-2023-1736_published_version.pdf"                                                              </span></span>
<span><span class="co">## [16] "Noy_Zhang_1.pdf"                                                                                  </span></span>
<span><span class="co">## [17] "sd-2024-09-falck-etal-kuenstliche-intelligenz-unternehmen.pdf"                                    </span></span>
<span><span class="co">## [18] "ssrn-4700751.pdf"                                                                                 </span></span>
<span><span class="co">## [19] "SSRN-id4573321.pdf"                                                                               </span></span>
<span><span class="co">## [20] "The Simple Macroeconomics of AI.pdf"                                                              </span></span>
<span><span class="co">## [21] "w24001.pdf"                                                                                       </span></span>
<span><span class="co">## [22] "w24871.pdf"                                                                                       </span></span>
<span><span class="co">## [23] "w31161.pdf"                                                                                       </span></span>
<span><span class="co">## [24] "w32430.pdf"</span></span></code></pre></div>
<p>Our goal is to get a first overview of these papers and what they are
about and to give them good file names.</p>
<div class="section level3">
<h3 id="step-1-setting-up-the-document-prompt">Step 1: Setting up the Document Prompt<a class="anchor" aria-label="anchor" href="#step-1-setting-up-the-document-prompt"></a>
</h3>
<p>First, we create a prompt designed to elicit detailed responses for
each document. This structured prompt asks for specific metadata like
title, authors, and type, along with deeper content-related questions
about empirical methods and theoretical frameworks.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">document_prompt</span> <span class="op">&lt;-</span> <span class="st">'</span></span>
<span><span class="st">Below are the first 5 pages of a document. Answer the questions below in detail.</span></span>
<span><span class="st">Provide each answer as a standalone response. </span></span>
<span><span class="st"></span></span>
<span><span class="st">1. Title: Provide the full, exact title of the document as it appears on the first page.</span></span>
<span><span class="st">2. Authors: List all authors as stated in the document, including any institutional affiliations if mentioned.</span></span>
<span><span class="st">3. Suggested Filename: Suggest a filename in the format "ReleaseYear_Author_etal_ShortTitle.pdf". Use the publication year if available; otherwise, use XXXX.</span></span>
<span><span class="st">4. Document Type: Specify if this is a "Policy Report" or a "Research Paper" based on the document’s style, structure, and purpose.</span></span>
<span><span class="st">5. Key Citations: Identify the four most frequently cited or critical references in the first 5 pages that support the document’s primary claims or background.</span></span>
<span><span class="st"></span></span>
<span><span class="st">Additionally, answer the following questions about the document’s content. Each answer should be concise but comprehensive, ideally 150 words:</span></span>
<span><span class="st"></span></span>
<span><span class="st">6. Empirical Methods: Describe any empirical methods used, including data collection, statistical techniques, or analysis methods mentioned.</span></span>
<span><span class="st">7. Theoretical Framework: Outline the primary theoretical framework or models discussed, if any, that underpin the analysis or arguments.</span></span>
<span><span class="st">8. Main Point: Summarize the central argument or main point the document presents.</span></span>
<span><span class="st">9. Key Contribution: Explain the unique contribution of this document, particularly what it adds to the field or topic.</span></span>
<span><span class="st">'</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="step-2-generating-messages-for-each-document">Step 2: Generating Messages for Each Document<a class="anchor" aria-label="anchor" href="#step-2-generating-messages-for-each-document"></a>
</h3>
<p>Next, we prepare a list of messages for all PDFs in the folder by
applying <code><a href="../reference/llm_message.html">llm_message()</a></code> with the prompt to the first five
pages of each document. This step sets up a list of messages, where each
entry specifies a task to retrieve structured answers on one file. Even
though the <code>gpt-4o-mini model</code> we will use in this example
can process up to 128,000 tokens -approximately 80-90 pages of English
text- we limit the input to five pages for demonstration purposes and to
maintain focus on the introduction that is usually enough to get a first
overview of a paper.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">document_tasks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="va">files</span>,<span class="op">~</span><span class="fu"><a href="../reference/llm_message.html">llm_message</a></span><span class="op">(</span><span class="va">document_prompt</span>, </span>
<span>            .pdf <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>              filename <span class="op">=</span> <span class="va">.x</span>,</span>
<span>              start_page <span class="op">=</span> <span class="fl">1</span>,</span>
<span>              end_page <span class="op">=</span> <span class="fl">5</span><span class="op">)</span><span class="op">)</span> <span class="co">#Maximally 5 pages since we are not sure how long each document is</span></span>
<span><span class="op">)</span> </span></code></pre></div>
</div>
<div class="section level3">
<h3 id="step-3-defining-the-schema-for-structured-output">Step 3: Defining the Schema for Structured Output<a class="anchor" aria-label="anchor" href="#step-3-defining-the-schema-for-structured-output"></a>
</h3>
<p>In this step, we define a schema that outlines the expected data
types for each field in the model’s responses. This schema enables the
large language model to return answers in a structured, consistent
format that can later be converted into a table, making it easy to
analyze and compare results across documents.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">document_schema</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tidyllm_schema.html">tidyllm_schema</a></span><span class="op">(</span></span>
<span>  name <span class="op">=</span> <span class="st">"DocumentAnalysisSchema"</span>,</span>
<span>  Title <span class="op">=</span> <span class="st">"character"</span>,</span>
<span>  Authors <span class="op">=</span> <span class="st">"character"</span>,</span>
<span>  SuggestedFilename <span class="op">=</span> <span class="st">"character"</span>,</span>
<span>  Type <span class="op">=</span> <span class="st">"factor(Policy, Research)"</span>,</span>
<span>  Empirics <span class="op">=</span> <span class="st">"character"</span>,</span>
<span>  Theory <span class="op">=</span> <span class="st">"character"</span>,</span>
<span>  MainPoint <span class="op">=</span> <span class="st">"character"</span>,</span>
<span>  Contribution <span class="op">=</span> <span class="st">"character"</span>,</span>
<span>  KeyCitations <span class="op">=</span> <span class="st">"character"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>In <code><a href="../reference/tidyllm_schema.html">tidyllm_schema()</a></code>, we specify each field along with
its expected data type. Supported types include <code>character</code>
(with <code>string</code> as an accepted synonym), <code>logical</code>,
and <code>numeric</code>. For fields where categorical responses are
needed, we can use <code><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor()</a></code> to define specific allowed
options. For instance, <code>factor(Policy, Research)</code> creates a
categorical field with the choices “Policy” and “Research.” To indicate
that a field should return a list of values, we append <code>[]</code>
to the type. For example, setting <code>Authors = "character[]"</code>
allows multiple entries in a list format for the Authors field. However,
we intentionally avoid lists here to maintain a flat structure. This
ensures that the output can be easily converted to a single-row
<code>tibble</code>. <code>name</code> is a special field, which creates
an identifier for a schema. By default it is
<code>"tidyllm_schema"</code></p>
</div>
<div class="section level3">
<h3 id="step-4-running-the-analysis-on-a-sample-document">Step 4: Running the Analysis on a Sample Document<a class="anchor" aria-label="anchor" href="#step-4-running-the-analysis-on-a-sample-document"></a>
</h3>
<p>To test the setup, we run the analysis on a single document with the
standard <code><a href="../reference/chat.html">chat()</a></code> function, using the schema to ensure
structured output.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">example_task</span> <span class="op">&lt;-</span> <span class="va">document_tasks</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/chat.html">chat</a></span><span class="op">(</span><span class="fu"><a href="../reference/openai.html">openai</a></span><span class="op">(</span>.json_schema <span class="op">=</span> <span class="va">document_schema</span>,</span>
<span>              .model       <span class="op">=</span> <span class="st">"gpt-4o-mini"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="step-5-extracting-and-formatting-the-results-for-our-example-task">Step 5: Extracting and Formatting the Results for our example
task<a class="anchor" aria-label="anchor" href="#step-5-extracting-and-formatting-the-results-for-our-example-task"></a>
</h3>
<p>We use <code><a href="../reference/get_reply_data.html">get_reply_data()</a></code> to extract the model’s
structured responses from the model reply.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/get_reply_data.html">get_reply_data</a></span><span class="op">(</span><span class="va">example_task</span><span class="op">)</span></span>
<span><span class="co">## $Title</span></span>
<span><span class="co">## [1] "A Method to Link Advances in Artificial Intelligence to Occupational Abilities"</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $Authors</span></span>
<span><span class="co">## [1] "Edward W. Felten (Princeton University), Manav Raj (NYU Stern School of Business), Robert Seamans (NYU Stern School of Business)"</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $SuggestedFilename</span></span>
<span><span class="co">## [1] "2018_Felten_etal_AILinkOccupations.pdf"</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $Type</span></span>
<span><span class="co">## [1] "Research"</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $Empirics</span></span>
<span><span class="co">## [1] "The paper employs empirical methods using two databases: the Electronic Frontier Foundation AI Progress Measurement dataset and the Occupational Information Network (O*NET) from the US Department of Labor. The authors collect data on AI progress metrics and correlate these with occupational definitions and the abilities required for various jobs to derive impact scores for the effect of AI advancements on occupations."</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $Theory</span></span>
<span><span class="co">## [1] "The primary theoretical framework is based on task variation in occupations and the effects of AI on the bundle of skills required for specific occupations. The authors complement the work of previous scholars by linking advancements in AI technologies directly to job abilities, rather than relying solely on expert predictions about AI's future impact."</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $MainPoint</span></span>
<span><span class="co">## [1] "The document presents a new methodology to link advancements in artificial intelligence to the abilities required in various occupations. It highlights how AI affects the nature of labor, suggesting significant implications for understanding job susceptibility to automation and changes in job requirements."</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $Contribution</span></span>
<span><span class="co">## [1] "The key contribution of this research is the development of a systematic methodology to assess how AI advancements impact specific occupational abilities. This approach enables researchers, practitioners, and policymakers to analyze and compare the potential threats and opportunities posed by AI across different job sectors, guiding informed decisions and policies regarding technology and labor market adaptation."</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $KeyCitations</span></span>
<span><span class="co">## [1] "1. Autor, David H., and Anna Salomons. 2017; 2. Brynjolfsson, Erik, Tom Mitchell, and Daniel Rock. 2018; 3. Frey, Carl Benedikt, and Michael A. Osborne. 2017; 4. Graetz, Georg, and Guy Michaels. 2015."</span></span></code></pre></div>
<p>The model seems to have reasonably answered our questions in the
structured format we provided for our first example task. Here we can
also look at the token usage of the example task:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/get_reply_data.html">get_reply_data</a></span><span class="op">(</span><span class="va">example_task</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## <span style="color: #949494;"># A tibble: 1 × 5</span></span></span>
<span><span class="co">##   model         timestamp           prompt_tokens completion_tokens total_tokens</span></span>
<span><span class="co">##   <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>         <span style="color: #949494; font-style: italic;">&lt;dttm&gt;</span>                      <span style="color: #949494; font-style: italic;">&lt;int&gt;</span>             <span style="color: #949494; font-style: italic;">&lt;int&gt;</span>        <span style="color: #949494; font-style: italic;">&lt;int&gt;</span></span></span>
<span><span class="co">## <span style="color: #BCBCBC;">1</span> gpt-4o-mini-… 2024-11-13 <span style="color: #949494;">07:41:29</span>          <span style="text-decoration: underline;">4</span>356               273         <span style="text-decoration: underline;">4</span>629</span></span></code></pre>
<p>At a price for <code>gpt-4o-mini</code> of $0.15 / million input
tokens and $0.60 / million output tokens the cost of our example task is
less than a cent.</p>
</div>
<div class="section level3">
<h3 id="step-6-scaling-up-to-a-whole-batch-of-papers">Step 6: Scaling up to a whole batch of papers<a class="anchor" aria-label="anchor" href="#step-6-scaling-up-to-a-whole-batch-of-papers"></a>
</h3>
<p>After confirming that our single-document analysis is working well,
we can extend this workflow to process a larger batch of documents.
Batch processing is particularly valuable when handling a large
collection of files, as it allows us to submit multiple messages at
once, which are then processed together on the model provider’s
servers.</p>
<p>Batch APIs, like those from Anthropic and OpenAI, often offer up to
50% savings compared to single-interaction requests. In
<strong>tidyllm</strong>, we can use <code><a href="../reference/send_batch.html">send_batch()</a></code> to submit
batch requests. The OpenAI Batch API, supports up to 50,000 requests in
a single batch with a maximum file size of 100 MB. Additionally, batch
API rate limits are separate from the standard per-model limits, meaning
batch usage doesn’t impact your regular API rate allocations.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">document_tasks</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/send_batch.html">send_batch</a></span><span class="op">(</span><span class="fu"><a href="../reference/openai.html">openai</a></span><span class="op">(</span>.json_schema <span class="op">=</span> <span class="va">document_schema</span>,</span>
<span>                     .model       <span class="op">=</span> <span class="st">"gpt-4o-mini"</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://readr.tidyverse.org/reference/read_rds.html" class="external-link">write_rds</a></span><span class="op">(</span><span class="st">"document_batch.rds"</span><span class="op">)</span></span></code></pre></div>
<p>After the batch is sent, the output of <code><a href="../reference/send_batch.html">send_batch()</a></code>
contains the input list of message histories along with batch metadata,
such as the <code>batchID</code> as an attribute as well as unique names
for each list element that can be used to stitch together messages with
replies, once they are ready. If you provide a named list of messages,
<strong>tidyllm</strong> will use these names as identifiers in the
batch (provided that these names are unique for each list element).
Batches are processed within 24 hours, usually much faster. The batch
request for this example was processed within 10 minutes.</p>
<blockquote>
<p>⚠️ <strong>Note:</strong> We save the RDS file to disk to preserve
the state of our batch request, including all messages and their unique
identifiers. This file acts as a checkpoint, allowing us to easily
reload and check the batch status or retrieve results across R sessions
without needing to resend the entire batch if we close the session in
the mean time.</p>
</blockquote>
<p>To check whether a batch was compeleted you can load the output file
into <code><a href="../reference/check_openai_batch.html">check_openai_batch()</a></code>:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://readr.tidyverse.org/reference/read_rds.html" class="external-link">read_rds</a></span><span class="op">(</span><span class="st">"document_batch.rds"</span><span class="op">)</span><span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/check_batch.html">check_batch</a></span><span class="op">(</span><span class="va">openai</span><span class="op">)</span></span></code></pre></div>
<p>Alternatively you can list all OpenAI batches with
<code><a href="../reference/list_openai_batches.html">list_openai_batches()</a></code>or
<code>list_batchers(openai())</code>. Of course, you can also look into
the <a href="https://platform.openai.com/batches/" class="external-link">batches dashboard of
the OpenAI platform</a> for the same overview. Since OpenAI batches are
sent as <code>.jsonl</code> and saved on the OpenAI server, you can also
look into the file tab of the dashboard to delete old files from time to
time.</p>
</div>
<div class="section level3">
<h3 id="step-7-getting-data-from-the-entire-batch">Step 7: Getting data from the entire batch<a class="anchor" aria-label="anchor" href="#step-7-getting-data-from-the-entire-batch"></a>
</h3>
<p>Once the batch is complete, we fetch all responses with
<code><a href="../reference/fetch_batch.html">fetch_batch()</a></code>:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_rds.html" class="external-link">read_rds</a></span><span class="op">(</span><span class="st">"document_batch.rds"</span><span class="op">)</span><span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/fetch_batch.html">fetch_batch</a></span><span class="op">(</span><span class="va">openai</span><span class="op">)</span></span></code></pre></div>
<p>We can then process the results into a table by mapping
<code><a href="../reference/get_reply_data.html">get_reply_data()</a></code> and <code><a href="https://tibble.tidyverse.org/reference/as_tibble.html" class="external-link">as_tibble()</a></code> over the
batch output:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">docuemnt_table</span> <span class="op">&lt;-</span> <span class="va">results</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="va">get_reply_data</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map_dfr.html" class="external-link">map_dfr</a></span><span class="op">(</span><span class="va">as_tibble</span><span class="op">)</span></span>
<span>  </span>
<span><span class="va">docuemnt_table</span></span>
<span><span class="co">## <span style="color: #949494;"># A tibble: 24 × 9</span></span></span>
<span><span class="co">##    Title  Authors SuggestedFilename Type  Empirics Theory MainPoint Contribution</span></span>
<span><span class="co">##    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>             <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>     <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>       </span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 1</span> A Met… Edward… 2018_Felten_etal… Rese… The doc… The t… The docu… This paper'…</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 2</span> The R… Alexan… 2024_Bick_etal_R… Rese… The pap… The f… The cent… The documen…</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 3</span> THE A… Andrew… 2024_Caplin_etal… Rese… The doc… The d… The cent… The paper's…</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 4</span> Large… John J… 2023_Horton_etal… Rese… The pap… The p… The cent… The documen…</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 5</span> The I… Sida P… 2023_Peng_etal_G… Rese… Conduct… Theor… The stud… This resear…</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 6</span> GPTs … Tyna E… 2023_Eloundou_et… Rese… The stu… The d… The cent… The paper p…</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 7</span> Autom… Philip… 2023_Lergetporer… Rese… The stu… The t… The docu… This resear…</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 8</span> Artif… Andrew… 2024_Green_etal_… Rese… The rep… The t… The cent… This docume…</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 9</span> THE A… Andrew… 2024_Caplin_etal… Rese… The res… The p… The docu… This docume…</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">10</span> Autom… Daron … 2019_Acemoglu_Re… Rese… The pap… The t… The docu… This paper …</span></span>
<span><span class="co">## <span style="color: #949494;"># ℹ 14 more rows</span></span></span>
<span><span class="co">## <span style="color: #949494;"># ℹ 1 more variable: KeyCitations &lt;chr&gt;</span></span></span></code></pre></div>
<p>This table can be exported to Excel with
<code><a href="https://docs.ropensci.org/writexl/reference/write_xlsx.html" class="external-link">writexl::write_xlsx()</a></code> for further review. Additionally, we
could programmatically rename the PDFs using the model’s suggested
filenames, helping maintain an organized document structure for future
analysis.</p>
</div>
</div>
<div class="section level2">
<h2 id="further-notes-on-working-with-large-documents">Further notes on working with large documents<a class="anchor" aria-label="anchor" href="#further-notes-on-working-with-large-documents"></a>
</h2>
<div class="section level3">
<h3 id="context-length">Context length<a class="anchor" aria-label="anchor" href="#context-length"></a>
</h3>
<p>When working with long documents like research papers, reports, or
books, one common challenge is context length—the maximum amount of text
the model can process in a single query. If a document exceeds this
limit, the model will only see a portion of it, which may lead to
missing important sections or incomplete answers.</p>
<p>In most models, context length is measured in
<strong>tokens</strong>, the basic units of text. For example, many
small local models have a maximum context length of around 8,192 tokens,
roughly covering 30–35 pages. This means that for a long academic paper,
the model may only see the beginning of the document, potentially
omitting later sections like bibliographies or appendices, where key
references or results might appear. Moreover, appending a whole document
to a prompt might leave your actual prompt out of the context.</p>
<p>To manage this, a common approach is to limit the number of pages
sent to the model. In this workflow, we focus on the first five pages
for an initial overview. This typically includes the abstract,
introduction, methodology, results, and discussion—enough to capture the
essence of the paper. While this approach ensures that the model can
process core content, it may omit information found in later
sections.</p>
<p>Alternatively, for very large documents, you could split them into
smaller sections and process each separately, covering more content
without exceeding the model’s context window. However, splitting can
disrupt the document’s flow, which may affect how well the model retains
context across sections.</p>
</div>
<div class="section level3">
<h3 id="gemini-for-image-heavy-pdfs">Gemini for image-heavy PDFs<a class="anchor" aria-label="anchor" href="#gemini-for-image-heavy-pdfs"></a>
</h3>
<p>For <code><a href="../reference/gemini.html">gemini()</a></code> there is an alternative to adding the text
from a PDF with <code><a href="../reference/llm_message.html">llm_message()</a></code>. You can directly upload a
PDF to Google’s servers with <code><a href="../reference/gemini_upload_file.html">gemini_upload_file()</a></code> and use
it in the context of your messages. The advantage of this approach is
that Gemini can handle images in PDFs or are even image-only PDFs (such
as scanned documents). See the article on <a href="https://edubruell.github.io/tidyllm/articles/tidyllm_video.html">Video
and Audio Data with the Gemini API</a> for an example how to use the
<code><a href="../reference/gemini_upload_file.html">gemini_upload_file()</a></code> feature.</p>
</div>
<div class="section level3">
<h3 id="local-models">Local Models<a class="anchor" aria-label="anchor" href="#local-models"></a>
</h3>
<p>Using open-source local models for PDF processing is also possible,
though remote models like <code>gpt-4o-mini</code> tend to handle longer
documents more effectively. Smaller local models, like
<code>gemma2:9B</code> in <code><a href="../reference/ollama.html">ollama()</a></code>, may struggle with large
content and complex, structured queries, even if they support extended
context lengths. For more demanding tasks, larger local models like
<code>llama3:70B</code> may perform better with complex queries, but
they require substantial hardware resources to run smoothly. Since
Ollama has a default context length of just 2,048 tokens, you will
likely need to adjust the context length with the <code>.num_ctx</code>
option in <code><a href="../reference/ollama.html">ollama()</a></code>. Sending a message that is longer than
the context length might lead to strange errors, since the input will be
truncated by Ollama, which might lead to cases where only parts of the
document are processed without your instructions. Note that increasing
context length will likely slow down processing due to higher memory
usage. In these cases, reducing the number of pages may help.</p>
<blockquote>
<p>⚠️ <strong>Note:</strong> When using paid remote models, it’s
important to consider data privacy and security, especially if you’re
processing sensitive documents, as uploading data to external servers
may introduce risks — local models provide more control in such
cases.</p>
</blockquote>
</div>
</div>
<div class="section level2">
<h2 id="outlook">Outlook<a class="anchor" aria-label="anchor" href="#outlook"></a>
</h2>
<p>This structured question-answering workflow not only streamlines the
extraction of key insights from academic papers, but can also be adapted
for other document-heavy tasks. Whether you’re working with reports,
policy documents, or news articles this approach can quickly help you
summarize and categorize information for further analysis.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Eduard Brüll.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
