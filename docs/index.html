<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Tidy Integration of Large Language Models • tidyllm</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="apple-touch-icon-60x60.png">
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Tidy Integration of Large Language Models">
<meta name="description" content="A tidy interface for integrating large language model (LLM) APIs such as Claude, Openai, Groq,Mistral and local models via Ollama into R workflows. The package supports text and media-based interactions, interactive message history, batch request APIs, and a tidy, pipeline-oriented interface for streamlined integration into data workflows. Web services are available at &lt;https://www.anthropic.com&gt;, &lt;https://openai.com&gt;, &lt;https://groq.com&gt;, &lt;https://mistral.ai/&gt; and &lt;https://ollama.com&gt;.">
<meta property="og:description" content="A tidy interface for integrating large language model (LLM) APIs such as Claude, Openai, Groq,Mistral and local models via Ollama into R workflows. The package supports text and media-based interactions, interactive message history, batch request APIs, and a tidy, pipeline-oriented interface for streamlined integration into data workflows. Web services are available at &lt;https://www.anthropic.com&gt;, &lt;https://openai.com&gt;, &lt;https://groq.com&gt;, &lt;https://mistral.ai/&gt; and &lt;https://ollama.com&gt;.">
<meta property="og:image" content="https://edubruell.github.io/tidyllm/logo.png">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">tidyllm</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.3.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="articles/tidyllm.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="articles/tidyllm_classifiers.html">Classifying Texts with tidyllm</a></li>
    <li><a class="dropdown-item" href="articles/tidyllm_embed.html">Embedding Models in tidyllm</a></li>
    <li><a class="dropdown-item" href="articles/tidyllm_video.html">Video and Audio Data with the Gemini API</a></li>
    <li><a class="dropdown-item" href="articles/tidyllm-pdfquestions.html">Structured Question Answering from PDFs</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/edubruell/tidyllm/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><div class="section level1">
<div class="page-header">
<img src="logo.png" class="logo" alt=""><h1 id="tidyllm-">tidyllm 
<a class="anchor" aria-label="anchor" href="#tidyllm-"></a>
</h1>
</div>
<p><a href="https://opensource.org/licenses/MIT" class="external-link"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT"></a> <a href="https://cran.r-project.org/package=tidyllm" class="external-link"><img src="https://www.r-pkg.org/badges/version/tidyllm" alt="CRAN Status"></a></p>
<p><strong>tidyllm</strong> is an R package designed to access various large language model APIs, including <strong>Anthropic Claude</strong>, <strong>OpenAI</strong>,<strong>Google Gemini</strong>, <strong>Perplexity</strong>,<strong>Groq</strong>, <strong>Mistral</strong>, and local models via <strong>Ollama</strong> or OpenAI-compatible APIs. Built for simplicity and functionality, it helps you generate text, analyze media, and integrate model feedback into your data workflows with ease.</p>
<div class="section level2">
<h2 id="features">Features<a class="anchor" aria-label="anchor" href="#features"></a>
</h2>
<ul>
<li>
<strong>Multiple Model Support</strong>: Seamlessly switch between various model providers using the best of what each has to offer.</li>
<li>
<strong>Media Handling</strong>: Extract and process text from PDFs and capture console outputs for messaging. Upload imagefiles or the last plotpane to multimodal models. For the Gemini API even video and audio inputs are supported.</li>
<li>
<strong>Interactive Messaging History</strong>: Manage an ongoing conversation with models, maintaining a structured history of messages and media interactions, which are automatically formatted for each API</li>
<li>
<strong>Batch processing:</strong> Efficiently handle large workloads with Anthropic, OpenAI or Mistral batch processing APIs, reducing costs by up to 50%.</li>
<li>
<strong>Tidy Workflow</strong>: Use R’s functional programming features for a side-effect-free, pipeline-oriented operation style.</li>
</ul>
</div>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<p>To install <strong>tidyllm</strong> from CRAN, use:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"tidyllm"</span><span class="op">)</span></span></code></pre></div>
<p>Or for the development version from GitHub:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Install devtools if not already installed</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/ns-load.html" class="external-link">requireNamespace</a></span><span class="op">(</span><span class="st">"devtools"</span>, quietly <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"devtools"</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="fu">devtools</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html" class="external-link">install_github</a></span><span class="op">(</span><span class="st">"edubruell/tidyllm"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="basic-example">Basic Example<a class="anchor" aria-label="anchor" href="#basic-example"></a>
</h2>
<p>Here’s a quick example using tidyllm to describe an image using the Claude model to and follow up with local open-source models:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://edubruell.github.io/tidyllm/">"tidyllm"</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Describe an image with  claude</span></span>
<span><span class="va">conversation</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/llm_message.html">llm_message</a></span><span class="op">(</span><span class="st">"Describe this image"</span>, </span>
<span>                              .imagefile <span class="op">=</span> <span class="fu">here</span><span class="op">(</span><span class="st">"image.png"</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="reference/chat.html">chat</a></span><span class="op">(</span><span class="fu"><a href="reference/claude.html">claude</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Use the description to query further with groq</span></span>
<span><span class="va">conversation</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="reference/llm_message.html">llm_message</a></span><span class="op">(</span><span class="st">"Based on the previous description,</span></span>
<span><span class="st">  what could the research in the figure be about?"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="reference/chat.html">chat</a></span><span class="op">(</span><span class="fu"><a href="reference/ollama.html">ollama</a></span><span class="op">(</span>.model <span class="op">=</span> <span class="st">"gemma2"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>For more examples and advanced usage, check the <a href="https://edubruell.github.io/tidyllm/articles/tidyllm.html">Get Started vignette</a>.</p>
<p>Please note: To use <strong>tidyllm</strong>, you need either an installation of <strong>ollama</strong> or an active API key for one of the supported providers (e.g., Claude, ChatGPT). See the <a href="https://edubruell.github.io/tidyllm/articles/tidyllm.html">Get Started vignette</a> for setup instructions.</p>
</div>
<div class="section level2">
<h2 id="interface-change-in-last-release">Interface-change in last release<a class="anchor" aria-label="anchor" href="#interface-change-in-last-release"></a>
</h2>
<p>The last CRAN release of <strong>tidyllm</strong>, introduces a major interface change to provide a more intuitive user experience. Previously, provider-specific functions like <code><a href="reference/claude.html">claude()</a></code>, <code><a href="reference/openai.html">openai()</a></code>, and others were directly used for chat-based workflows. They specified both an API-provider and performed a chat-interaction. Now, these functions primarily serve as provider configuration for more general verbs like <code><a href="reference/chat.html">chat()</a></code>,<code><a href="reference/embed.html">embed()</a></code> or <code><a href="reference/send_batch.html">send_batch()</a></code>. A combination of a general verb and a provider will always route requests to a provider-specific function like <code><a href="reference/openai_chat.html">openai_chat()</a></code>. Read the <a href="https://edubruell.github.io/tidyllm/news/">Changelog</a> or the <a href="https://edubruell.github.io/tidyllm/articles/tidyllm.html">package vignette</a> for more information.</p>
<p>For backward compatibility, the old use of functions like <code><a href="reference/openai.html">openai()</a></code> or <code><a href="reference/claude.html">claude()</a></code> directly for chat requests still works but now but issues deprecation warnings. It is recommended to either use the verb-based interface:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/llm_message.html">llm_message</a></span><span class="op">(</span><span class="st">"Hallo"</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="reference/chat.html">chat</a></span><span class="op">(</span><span class="fu"><a href="reference/openai.html">openai</a></span><span class="op">(</span>.model<span class="op">=</span><span class="st">"gpt-4o"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>or to use the more verbose provider-specific functions directly:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/llm_message.html">llm_message</a></span><span class="op">(</span><span class="st">"Hallo"</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="reference/openai_chat.html">openai_chat</a></span><span class="op">(</span>.model<span class="op">=</span><span class="st">"gpt-4o"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="learn-more">Learn More<a class="anchor" aria-label="anchor" href="#learn-more"></a>
</h2>
<p>For detailed instructions and advanced features, see:</p>
<ul>
<li><a href="https://edubruell.github.io/tidyllm/articles/tidyllm.html">Get Started with tidyllm</a></li>
<li><a href="https://edubruell.github.io/tidyllm/news/">Changelog</a></li>
<li><a href="https://edubruell.github.io/tidyllm/">Documentation</a></li>
<li>Use-case oriented articles:
<ul>
<li><a href="https://edubruell.github.io/tidyllm/articles/tidyllm_classifiers.html">Classifying Texts with tidyllm</a></li>
<li><a href="https://edubruell.github.io/tidyllm/articles/tidyllm-pdfquestions.html">Structured Question Answering from PDFs</a></li>
<li><a href="https://edubruell.github.io/tidyllm/articles/tidyllm_embed.html">Using Embedding Models for Semantic Search</a></li>
<li><a href="https://edubruell.github.io/tidyllm/articles/tidyllm_video.html">Video and Audio Data with the Gemini API</a></li>
</ul>
</li>
</ul>
</div>
<div class="section level2">
<h2 id="similar-packages">Similar packages<a class="anchor" aria-label="anchor" href="#similar-packages"></a>
</h2>
<p>The are some similar R packages for working with LLMs:</p>
<ul>
<li>
<a href="https://ellmer.tidyverse.org/" class="external-link">ellmer</a> is especially great for asynchronous workflows, chatbots in Shiny and advanced tool-calling capabilities. Its schema functions offer robust support for complex structured data extraction, making it a great choice for applications that require highly interactive or structured LLM interactions. While <strong>ellmer</strong>’s feature set overlaps with <strong>tidyllm</strong> in some areas, its interface and design philosophy are very different.</li>
<li>
<a href="https://jbgruber.github.io/rollama/" class="external-link">rollama</a> is specifically designed to support the Ollama API, enabling seamless interaction with local LLM models. A key strength of <strong>rollama</strong> lies in its specialized Ollama API functionalities, such as <code>copy</code>, <code>create</code>, and <code>delete</code>, which are not currently available in <strong>tidyllm</strong>. These features make <strong>rollama</strong> particularly suited for workflows requiring model management or deployment within the Ollama ecosystem.</li>
</ul>
</div>
<div class="section level2">
<h2 id="contributing">Contributing<a class="anchor" aria-label="anchor" href="#contributing"></a>
</h2>
<p>We welcome contributions! Feel free to open issues or submit pull requests on <a href="https://github.com/edubruell/tidyllm" class="external-link">GitHub</a>.</p>
</div>
<div class="section level2">
<h2 id="license">License<a class="anchor" aria-label="anchor" href="#license"></a>
</h2>
<p>This project is licensed under the MIT License - see the <a href="https://opensource.org/licenses/MIT" class="external-link">LICENSE</a> file for details.</p>
</div>
</div>
  </main><aside class="col-md-3"><div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li><a href="https://cloud.r-project.org/package=tidyllm" class="external-link">View on CRAN</a></li>
<li><a href="https://github.com/edubruell/tidyllm/" class="external-link">Browse source code</a></li>
<li><a href="https://github.com/edubruell/tidyllm/issues" class="external-link">Report a bug</a></li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li><a href="LICENSE.html">Full license</a></li>
<li><small><a href="https://opensource.org/licenses/mit-license.php" class="external-link">MIT</a> + file <a href="LICENSE-text.html">LICENSE</a></small></li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing tidyllm</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Eduard Brüll <br><small class="roles"> Author, maintainer </small>  </li>
<li><a href="authors.html">More about authors...</a></li>
</ul>
</div>



  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Eduard Brüll.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
